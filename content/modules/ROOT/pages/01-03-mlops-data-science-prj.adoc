= MLOps - Building up the Data Science Project

A Data Science Project was already created for each of you, but you will now need to fill it out with various items.

In this section, each of you will

. Open you Data Science project
** the project helps keep your things together

. Create a Data Connection
** we need that for the pipeline server to store its artifacts

. Deploy a Data Science Pipeline Server
** we will need one, and it's better to create it from the start

. Launch a Workbench
** we will use it to review content and notebooks

. Clone the git repo into your Workbench
** this contains all the code for the prototype model

== Open your project

* If you completed the last section you should be looking at the main view into OpenShift AI Dashboard application

[.bordershadow]
image::01-03/OCP-AI-MainView.png[width=75%]


* In the OpenShift AI Dashboard application, navigate to the Data Science Projects menu on the left

IMPORTANT: Your assigned user is {user}. Don't mess that up or things will break later on

* Click on your your Project link which should be {userX}-mlops

IMPORTANT: As a reminder, it should **NOT** be `userX` (for you, `X` should be a number instead)

[.bordershadow]
image::01-03/OCPAI-DataScience-Prjs.png[width=75%]

* You will now see the contents of your Data Science Project, which you will now finish building.

[.bordershadow]
image::01-03/OCPAI-DS-Prj-InitialView.png[]

== Create a Data Connection for the pipeline server

* We have deployed an instance of Minio in the cluster to act as a simple Object Storage for our purposes.
* You will need to **Add data connection** that points to it.
+
[.bordershadow]
image::01-03/AddDataConnection.png

* Here is the information you need to enter:
** Name:
[.lines_space]
[.console-input]
[source, text]
Minio Data Connection
** Access Key:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
{minio-user}
** Secret Key:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
{minio-pass}
** Endpoint:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
{minio-endpoint}
** Region:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
none
** Bucket:
[.lines_space]
[.console-input]
[source, text]
workbench

* The result should look like:
+
[.bordershadow]
image::01-03/AddDataConnection2.png[]

== Create a Pipeline Server

It is highly recommended to create your pipeline server before creating a workbench. So let's do that now!

* In your Data Science Project (DSP), click on **Configure a pipeline Server**
+
[.bordershadow]
image::01-03/pipelineserver01.png[]

* Select the Data Connection created earlier (**Minio Data Connection**) and click the **Configure** button:
+
[.bordershadow]
image::01-03/pipelineserver02.png[]

* When filling out your configuration, your screen will look like the following:
+
[.bordershadow]
image::01-03/pipelineserver03.png[]

* When your pipeline server is ready, your screen will look like the following:

[.bordershadow]
image::01-03/pipelineserver04.png[]
At this point, your pipeline server is ready and deployed.

IMPORTANT: You need to **wait** until that screen is ready. If it's still spinning, wait for it to complete. If you continue and create your workbench **before** the pipeline server is ready, your workbench will not be able to submit pipelines to it.


== Creating a workbench

* Once the Data Connection and Pipeline Server are fully created
* Create a workbench
+
[.bordershadow]
image::01-03/create-wb.png[]
* Make sure it has the following characteristics:
** Name
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
{user}Workbench
** Image selection `TensorFlow`
** Version selection `2023.2 (Recommended)`
** Container size `Medium`
** Accelerator `None`
** Cluster storage --> Create new persistent storage
** Name
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
{user}Workbench
+
NOTE: Don't change the Persistent storage size
+
** Use a data connection `check the box`
** Data connection `Minio Data Connection`
* That should look like:
+
** Top of workbench view
+
[.bordershadow]
image::01-03/launch-workbench-01.png[]

** Middle of workbench view
+
[.bordershadow]
image::01-03/launch-workbench-02.png[]
+
** Bottom of workbench view
+
[.bordershadow]
image::01-03/launch-workbench-03.png[]
+
* Wait for your workbench to be fully started
** Status will be `Running`
* Once it is, click the **Open** Link to connect to it.
+
[.bordershadow]
image::01-03/open-wb-link.png[]

* Authenticate with the same credentials as earlier
* You will be asked to accept the following settings:
** Click *Allow selected permissions*
+
[.bordershadow]
image::01-03/accept.png[]


* You should now see this:
+
[.bordershadow]
image::01-03/jupyter-mainview.png[]

== Git-Clone the common repo

We will clone the content of our Git repo so that you can access all the materials that were created as part of our prototyping exercise.

* Using the Git UI:
** Open the Git UI in Jupyter:
+
[.bordershadow]
image::01-03/git-clone-1.png[width=50%]
+
** Enter the URL of the Git repo:
+
[.console-input]
[source,adoc]
[subs=attributes+]
----
{git-clone-repo-url}
----
+
[.bordershadow]
image::01-03/git-clone-2.png[width=75%]

At this point, your project is ready for the work we want to do in it.

You should a view similar to this.
[.bordershadow]
image::01-03/initial-git-load-view.png[width=85%]

*Now lets move onto working with the Juypter notebooks and build some models.*